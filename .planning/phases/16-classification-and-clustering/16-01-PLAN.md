---
phase: 16-classification-and-clustering
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - orchestrator/drizzle/0009_pgvector_classification.sql
  - orchestrator/src/lib/db/schema.ts
  - orchestrator/src/lib/db/migrate-vectors.ts
autonomous: true

must_haves:
  truths:
    - "pgvector extension is enabled in database"
    - "Signals have native vector column for embeddings"
    - "Projects have native vector column for classification matching"
    - "Existing Base64 embeddings are migrated to native vector format"
    - "HNSW indexes enable O(log n) similarity search"
  artifacts:
    - path: "orchestrator/drizzle/0009_pgvector_classification.sql"
      provides: "pgvector extension and column migrations"
      contains: "CREATE EXTENSION"
    - path: "orchestrator/src/lib/db/schema.ts"
      provides: "embeddingVector columns on signals and projects"
      contains: "vector.*1536"
    - path: "orchestrator/src/lib/db/migrate-vectors.ts"
      provides: "Script to migrate Base64 embeddings to native vectors"
      contains: "base64ToEmbedding"
  key_links:
    - from: "orchestrator/src/lib/db/schema.ts"
      to: "drizzle-orm/pg-core"
      via: "vector type import"
      pattern: "customType|vector"
---

<objective>
Enable pgvector extension and migrate signal/project embeddings to native vector columns

Purpose: Phase 15 stores embeddings as Base64 text, which requires O(n) sequential scans for similarity search. Native pgvector columns with HNSW indexes enable O(log n) lookups required for classification and clustering at scale.

Output:
- Migration file enabling pgvector extension
- Native vector(1536) columns on signals and projects tables
- HNSW indexes for cosine similarity search
- Migration script to convert existing Base64 embeddings
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-classification-and-clustering/16-RESEARCH.md
@orchestrator/src/lib/db/schema.ts
@orchestrator/src/lib/ai/embeddings.ts
@orchestrator/package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pgvector Migration SQL</name>
  <files>orchestrator/drizzle/0009_pgvector_classification.sql</files>
  <action>
Create migration file with these SQL statements:

1. Enable pgvector extension:
```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

2. Add vector columns (keep existing Base64 as backup):
```sql
ALTER TABLE signals ADD COLUMN IF NOT EXISTS embedding_vector vector(1536);
ALTER TABLE projects ADD COLUMN IF NOT EXISTS embedding_vector vector(1536);
ALTER TABLE projects ADD COLUMN IF NOT EXISTS embedding_updated_at timestamp;
```

3. Add classification JSONB column to signals:
```sql
ALTER TABLE signals ADD COLUMN IF NOT EXISTS classification jsonb;
```

4. Create HNSW indexes for cosine similarity:
```sql
CREATE INDEX IF NOT EXISTS signals_embedding_vector_idx
ON signals USING hnsw (embedding_vector vector_cosine_ops);

CREATE INDEX IF NOT EXISTS projects_embedding_vector_idx
ON projects USING hnsw (embedding_vector vector_cosine_ops);
```

Note: The actual Base64 -> vector migration happens in Task 3 via TypeScript script (not in migration file). The migration file only adds columns and indexes.

Use `IF NOT EXISTS` / `IF EXISTS` for idempotency.
  </action>
  <verify>File exists at orchestrator/drizzle/0009_pgvector_classification.sql with CREATE EXTENSION, ALTER TABLE, and CREATE INDEX statements</verify>
  <done>Migration SQL file created with pgvector extension, vector columns, and HNSW indexes</done>
</task>

<task type="auto">
  <name>Task 2: Update Drizzle Schema with Vector Columns</name>
  <files>orchestrator/src/lib/db/schema.ts</files>
  <action>
Update schema.ts to add vector column support:

1. Create custom vector type (drizzle-orm pgvector support):
```typescript
import { customType } from "drizzle-orm/pg-core";

// Custom type for pgvector vector columns
export const vector = customType<{ data: number[]; driverData: string }>({
  dataType(config) {
    return `vector(${config?.dimensions ?? 1536})`;
  },
  toDriver(value: number[]): string {
    return `[${value.join(",")}]`;
  },
  fromDriver(value: string): number[] {
    // Parse pgvector format: [0.1,0.2,0.3,...]
    return value
      .slice(1, -1)
      .split(",")
      .map((v) => parseFloat(v));
  },
});
```

2. Add to signals table (after existing embedding text column):
```typescript
// Native pgvector column (Phase 16 - for similarity search)
embeddingVector: vector("embedding_vector", { dimensions: 1536 }),

// Classification metadata (Phase 16)
classification: jsonb("classification").$type<SignalClassificationResult>(),
```

3. Add to projects table:
```typescript
// Embedding for signal classification (Phase 16)
embeddingVector: vector("embedding_vector", { dimensions: 1536 }),
embeddingUpdatedAt: timestamp("embedding_updated_at", { mode: "string" }),
```

4. Add SignalClassificationResult type near SignalClassification:
```typescript
// Classification result from Phase 16 classifier
export interface SignalClassificationResult {
  projectId?: string;
  projectName?: string;
  confidence: number;
  method: "embedding" | "llm" | "manual";
  isNewInitiative?: boolean;
  reason?: string;
  classifiedAt: string;
}
```

Keep existing `embedding` (text) column as backup during transition. Do NOT remove it.
  </action>
  <verify>TypeScript compiles with `npx tsc --noEmit`. Schema includes embeddingVector on signals and projects, SignalClassificationResult type exists.</verify>
  <done>Drizzle schema updated with custom vector type and new columns for signals and projects</done>
</task>

<task type="auto">
  <name>Task 3: Create Vector Migration Script</name>
  <files>orchestrator/src/lib/db/migrate-vectors.ts</files>
  <action>
Create TypeScript script to migrate existing Base64 embeddings to native vector format:

```typescript
/**
 * Vector Migration Script
 *
 * Migrates existing Base64-encoded embeddings in signals.embedding
 * to native pgvector format in signals.embedding_vector.
 *
 * Run with: npx tsx src/lib/db/migrate-vectors.ts
 */

import { db } from "./index";
import { signals } from "./schema";
import { eq, isNull, isNotNull, and } from "drizzle-orm";
import { base64ToEmbedding } from "@/lib/ai/embeddings";

const BATCH_SIZE = 100;

async function migrateSignalVectors() {
  console.log("Starting signal vector migration...");

  let migrated = 0;
  let failed = 0;
  let hasMore = true;

  while (hasMore) {
    // Find signals with Base64 embedding but no vector
    const batch = await db
      .select({
        id: signals.id,
        embedding: signals.embedding,
      })
      .from(signals)
      .where(
        and(
          isNotNull(signals.embedding),
          isNull(signals.embeddingVector)
        )
      )
      .limit(BATCH_SIZE);

    if (batch.length === 0) {
      hasMore = false;
      break;
    }

    for (const signal of batch) {
      try {
        if (!signal.embedding) continue;

        // Convert Base64 to number array
        const vector = base64ToEmbedding(signal.embedding);

        // Validate vector dimensions
        if (vector.length !== 1536) {
          console.warn(`Signal ${signal.id}: Invalid vector dimension ${vector.length}`);
          failed++;
          continue;
        }

        // Update with native vector
        await db
          .update(signals)
          .set({ embeddingVector: vector })
          .where(eq(signals.id, signal.id));

        migrated++;
      } catch (error) {
        console.error(`Failed to migrate signal ${signal.id}:`, error);
        failed++;
      }
    }

    console.log(`Progress: ${migrated} migrated, ${failed} failed`);
  }

  console.log(`\nMigration complete: ${migrated} signals migrated, ${failed} failed`);
}

// Run if called directly
migrateSignalVectors()
  .then(() => process.exit(0))
  .catch((error) => {
    console.error("Migration failed:", error);
    process.exit(1);
  });
```

This script:
- Finds signals with Base64 embedding but no native vector
- Converts Base64 to number[] using existing utility
- Updates signals.embeddingVector with native vector
- Processes in batches of 100 for memory efficiency
- Logs progress and handles errors gracefully
  </action>
  <verify>File exists and TypeScript compiles. Script can be run with `npx tsx src/lib/db/migrate-vectors.ts`.</verify>
  <done>Migration script created to convert existing Base64 embeddings to native pgvector format</done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Migration file exists:
   ```bash
   ls orchestrator/drizzle/0009_pgvector_classification.sql
   ```

2. Schema compiles:
   ```bash
   cd orchestrator && npx tsc --noEmit
   ```

3. Vector type is defined:
   ```bash
   grep -n "customType" orchestrator/src/lib/db/schema.ts
   ```

4. embeddingVector columns exist in schema:
   ```bash
   grep -n "embeddingVector" orchestrator/src/lib/db/schema.ts
   ```

5. Migration script exists:
   ```bash
   ls orchestrator/src/lib/db/migrate-vectors.ts
   ```
</verification>

<success_criteria>
- pgvector extension migration SQL is created
- Drizzle schema has custom vector type and embeddingVector columns
- Migration script can convert Base64 embeddings to native vectors
- TypeScript compiles without errors
- All files committed to git
</success_criteria>

<output>
After completion, create `.planning/phases/16-classification-and-clustering/16-01-SUMMARY.md`
</output>
